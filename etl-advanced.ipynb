{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport multiprocessing\nimport logging\nimport pandas as pd\nfrom sqlalchemy import create_engine\n\n# Set up logging\nlogging.basicConfig(filename='etl.log', level=logging.INFO, format='%(asctime)s - %(levelname)s: %(message)s')\n\n# Function to extract data from multiple sources (e.g., CSV files)\ndef extract(source):\n    try:\n        data = pd.read_csv(source)\n        logging.info(f\"Extracted data from {source}\")\n        return data\n    except Exception as e:\n        logging.error(f\"Error extracting data from {source}: {str(e)}\")\n        return None\n\n# Function to transform data (e.g., clean, enrich, aggregate)\ndef transform(data):\n    try:\n        # Sample transformation: converting 'amount' column to uppercase\n        data['amount'] = data['amount'].str.upper()\n        logging.info(\"Transformed data\")\n        return data\n    except Exception as e:\n        logging.error(f\"Error transforming data: {str(e)}\")\n        return None\n\n# Function to load data into a database\ndef load(data, db_uri):\n    try:\n        engine = create_engine(db_uri)\n        data.to_sql('my_table', engine, if_exists='replace', index=False)\n        logging.info(\"Loaded data into database\")\n    except Exception as e:\n        logging.error(f\"Error loading data into database: {str(e)}\")\n\n# List of data sources\ndata_sources = ['data_source1.csv', 'data_source2.csv', 'data_source3.csv']\n\n# Define the number of parallel processes (adjust as needed)\nnum_processes = 3\n\nif __name__ == '__main__':\n    # Create a multiprocessing pool\n    pool = multiprocessing.Pool(processes=num_processes)\n    \n    # Extract data from multiple sources in parallel\n    extracted_data = pool.map(extract, data_sources)\n    \n    # Close the pool\n    pool.close()\n    pool.join()\n    \n    # Filter out None values (indicating extraction errors)\n    extracted_data = [data for data in extracted_data if data is not None]\n    \n    if extracted_data:\n        # Concatenate the extracted data\n        combined_data = pd.concat(extracted_data, ignore_index=True)\n        \n        # Transform the data\n        transformed_data = transform(combined_data)\n        \n        if transformed_data is not None:\n            # Load the transformed data into a database\n            db_uri = 'postgresql://username:password@localhost:5432/mydatabase'\n            load(transformed_data, db_uri)\n    else:\n        logging.error(\"No valid data to process.\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**This code demonstrates several advanced ETL concepts:**\n\nParallel Processing: It uses the multiprocessing module to extract data from multiple sources concurrently, improving performance.\n\nError Handling: It includes error handling with detailed logging, ensuring that errors are captured and logged.\n\nDatabase Interaction: It loads the transformed data into a PostgreSQL database using SQLAlchemy.\n\nLogging: It sets up logging to record extraction, transformation, and loading activities, which helps with monitoring and debugging.\n\nData Transformation: It applies a simple transformation (changing the 'amount' column to uppercase) as an example. You can customize this transformation to your needs.","metadata":{}}]}